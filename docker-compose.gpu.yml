services:
  # 作业3：基于 LangGraph 的多角色协作智能体系统（GPU版本）
  homework3-langgraph-agents-gpu:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: homework3-langgraph-agents-gpu
    volumes:
      # 挂载数据目录（数据库文件）
      - ./data:/app/data
      # 挂载日志目录
      - ./logs:/app/logs
      # 挂载缓存目录
      - ./cache:/app/cache
      # 注意：.env 文件不挂载，环境变量通过 environment 传递
    shm_size: '2gb'  # 共享内存大小
    environment:
      - PYTHONPATH=/app
      - PYTHONUNBUFFERED=1
      - PYTHONIOENCODING=utf-8
      - CUDA_VISIBLE_DEVICES=0
      # LLM API 配置（从环境变量读取）
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY:-}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - LLM_PROVIDER=${LLM_PROVIDER:-deepseek}
      - LLM_MODEL=${LLM_MODEL:-deepseek-chat}
      - LLM_TEMPERATURE=${LLM_TEMPERATURE:-0.7}
      - LLM_MAX_TOKENS=${LLM_MAX_TOKENS:-2000}
      # MCP 工具 API 配置（从环境变量读取）
      - WEATHER_SERVICE=${WEATHER_SERVICE:-mock}
      - QWEATHER_API_KEY=${QWEATHER_API_KEY:-}
      - OPENWEATHER_API_KEY=${OPENWEATHER_API_KEY:-}
      - AMAP_API_KEY=${AMAP_API_KEY:-}
      # 12306 火车票查询 MCP 服务配置
      - TRAIN_TICKET_SERVICE=${TRAIN_TICKET_SERVICE:-mock}
      - TRAIN_TICKET_MCP_COMMAND=${TRAIN_TICKET_MCP_COMMAND:-npx}
      - TRAIN_TICKET_MCP_ARGS=${TRAIN_TICKET_MCP_ARGS:--y,12306-mcp}
      # 时间查询 MCP 服务配置（使用 Python MCP 服务器）
      - TIME_MCP_COMMAND=${TIME_MCP_COMMAND:-python}
      - TIME_MCP_ARGS=${TIME_MCP_ARGS:--m tools.time_mcp_server}
      # 记忆/知识库 MCP 服务配置
      - MEMORY_MCP_COMMAND=${MEMORY_MCP_COMMAND:-npx}
      - MEMORY_MCP_ARGS=${MEMORY_MCP_ARGS:--y @modelcontextprotocol/server-memory}
      # 文件系统 MCP 服务配置（需要指定允许访问的目录）
      - FILESYSTEM_MCP_COMMAND=${FILESYSTEM_MCP_COMMAND:-npx}
      - FILESYSTEM_MCP_ARGS=${FILESYSTEM_MCP_ARGS:--y @modelcontextprotocol/server-filesystem /app/data /app/logs /app/cache}
      # 数据库配置
      - DATABASE_URL=sqlite:///./data/conversations.db
      # MCP 工具配置
      - MCP_SERVER_URL=${MCP_SERVER_URL:-http://localhost:8001}
      - KNOWLEDGE_BASE_URL=${KNOWLEDGE_BASE_URL:-http://localhost:8002}
      - ORDER_SERVICE_URL=${ORDER_SERVICE_URL:-http://localhost:8003}
      # 日志配置
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FILE=/app/logs/app.log
    ports:
      # 主服务端口（完整工作流）
      - "8000:8000"
      # 三个智能体独立服务端口
      - "8001:8001"  # 接待员智能体
      - "8002:8002"  # 问题分析师智能体
      - "8003:8003"  # 解决方案专家智能体
    restart: unless-stopped
    # NVIDIA GPU支持（RTX 5080）
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "python", "-c", "import torch; print('GPU available:', torch.cuda.is_available())"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    stdin_open: true
    tty: true
    networks:
      - homework3-network

networks:
  homework3-network:
    driver: bridge
